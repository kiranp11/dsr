{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-1fe33b9d2307>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/kprakash/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/kprakash/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/kprakash/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/kprakash/.pyenv/versions/3.6.5/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy import stats\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist.train.images\n",
    "X_test = mnist.test.images\n",
    "Y_train = mnist.train.labels\n",
    "Y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 1]]\n",
      "\n",
      "\n",
      "[[0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(y):\n",
    "    encoded = np.zeros((len(y), np.max(y)+1), dtype=\"uint8\")\n",
    "    encoded[np.arange(len(y)), y] = 1\n",
    "    assert len(y) == encoded.shape[0]    \n",
    "    return encoded\n",
    "\n",
    "\n",
    "print(one_hot_encode(np.r_[5,6,7]))\n",
    "print('\\n')\n",
    "print(one_hot_encode(np.r_[5,6,7,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_decode(y):\n",
    "    y = np.argmax(y, axis=1)\n",
    "    assert(len(y) == y.shape[0])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 785)\n",
      "(10000, 785)\n"
     ]
    }
   ],
   "source": [
    "Y_train2 = one_hot_encode(Y_train)\n",
    "Y_test2 = one_hot_encode(Y_test)\n",
    "\n",
    "# add a column of 1s as the new first column in X_train and X_test as the bias term 'c' in y = mx + c\n",
    "X_train2 = np.insert(X_train, 0, 1, axis=1)\n",
    "print(X_train2.shape)\n",
    "X_test2 = np.insert(X_test, 0, 1, axis=1)\n",
    "print(X_test2.shape)\n",
    "\n",
    "assert(np.all(X_train2[:,0] == 1.0))\n",
    "assert(X_train2.shape[1] == X_train.shape[1]+1)\n",
    "\n",
    "assert(np.all(X_test2[:,0] == 1.0))\n",
    "assert(X_test2.shape[1] == X_test.shape[1]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cases:\n",
    "assert np.all(one_hot_decode(one_hot_encode(Y_train)) == Y_train)\n",
    "assert np.all(one_hot_decode(one_hot_encode(Y_test)) == Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare variables\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None,785]) #X_train2, X_test2\n",
    "Y = tf.placeholder(tf.float32, [None,10]) #Y_train2, Y_test2\n",
    "A = tf.Variable(tf.random_normal((785,10))) # X @ A = Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(785, 10) dtype=float32_ref>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder:0' shape=(?, 785) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_pred = softmax(X_train2 @ A)\n",
    "\n",
    "Y_pred = tf.nn.softmax(tf.matmul(X,A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Softmax:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'truediv:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#     Y_pred = softmax(X_train2@A) # Y_pred.shape == (n,10)\n",
    "#     return -np.sum(Y_train2*np.log(Y_pred))/X_train2.shape[0]\n",
    "\n",
    "cross_entropy =  -tf.reduce_sum(Y*tf.log(Y_pred))/tf.cast(tf.shape(X), tf.float32)[0]\n",
    "cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-833560177337>:4: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n"
     ]
    }
   ],
   "source": [
    "#np.mean(np.argmax(Y_pred, axis=1) == np.argmax(Y_train2, axis=1))\n",
    "accuracy = tf.reduce_mean(\n",
    "    tf.cast(\n",
    "        tf.equal(tf.arg_max(Y_pred,1 ), tf.arg_max(Y, 1) ),\n",
    "        tf.float32\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.5 #learning rate\n",
    "#A = A - eta *  cross_entropy_grad(A,X,Y)\n",
    "train_step = tf.train.GradientDescentOptimizer(eta).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'GradientDescent' type=NoOp>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.922618\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "maxiter = 10000\n",
    "subset_size = X_train2.shape[0] // 100\n",
    "\n",
    "for i in range(maxiter):\n",
    "    #generate subset_size random indexes\n",
    "    idx = np.random.randint(X_train2.shape[0], size=subset_size)\n",
    "    sess.run(train_step, feed_dict={\n",
    "         X: X_train2[idx,:],\n",
    "         Y: Y_train2[idx,:]   \n",
    "    })\n",
    "\n",
    "print(sess.run(accuracy,feed_dict={\n",
    "         X: X_train2,\n",
    "         Y: Y_train2   \n",
    "    }))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0989818\n"
     ]
    }
   ],
   "source": [
    "A1 = tf.Variable(tf.random_normal( (785, 47) ))\n",
    "A2 = tf.Variable(tf.random_normal( (47, 10) ))\n",
    "Y_pred = tf.nn.softmax(\n",
    "    tf.matmul(tf.nn.relu(tf.matmul(X, A1)), A2)\n",
    ")\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(Y * tf.log(Y_pred))/tf.cast(tf.shape(X), tf.float32)[0]\n",
    "accuracy = tf.reduce_mean(\n",
    "    tf.cast(\n",
    "        tf.equal(tf.argmax(Y_pred, 1), tf.argmax(Y, 1))\n",
    "    , tf.float32)\n",
    ")\n",
    "train_step = tf.train.GradientDescentOptimizer(eta).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "maxiter = 10000\n",
    "subset_size = X_train2.shape[0] // 100\n",
    "for i in range(maxiter):\n",
    "    # generate subset_size random indexes\n",
    "    idx = np.random.randint(X_train2.shape[0], size=subset_size)\n",
    "    sess.run(train_step, feed_dict={\n",
    "        X: X_train2[idx,:],\n",
    "        Y: Y_train2[idx,:]\n",
    "    })\n",
    "\n",
    "print(sess.run(accuracy, feed_dict={\n",
    "        X: X_train2,\n",
    "        Y: Y_train2\n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 1s 15us/step - loss: 1.6848 - acc: 0.4781\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 1s 13us/step - loss: 0.9210 - acc: 0.7593\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 1s 13us/step - loss: 0.6492 - acc: 0.8195\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 1s 13us/step - loss: 0.4886 - acc: 0.8661\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 1s 13us/step - loss: 0.4293 - acc: 0.8806\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 1s 13us/step - loss: 0.3991 - acc: 0.8876\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 1s 13us/step - loss: 0.3795 - acc: 0.8933\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 1s 13us/step - loss: 0.3655 - acc: 0.8970\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 1s 13us/step - loss: 0.3544 - acc: 0.9000\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 1s 13us/step - loss: 0.3455 - acc: 0.9031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12780ff28>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=784))\n",
    "\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, Y_train2, epochs=10, batch_size=100, verbose=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 1s 16us/step - loss: 1.6110 - acc: 0.5153\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 1s 13us/step - loss: 1.0335 - acc: 0.6929\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 1s 13us/step - loss: 0.9090 - acc: 0.7112\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 1s 14us/step - loss: 0.8506 - acc: 0.7202\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 1s 13us/step - loss: 0.8159 - acc: 0.7254\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 1s 12us/step - loss: 0.7928 - acc: 0.7297\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 1s 12us/step - loss: 0.7763 - acc: 0.7330\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 1s 12us/step - loss: 0.7638 - acc: 0.7354\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 1s 12us/step - loss: 0.7540 - acc: 0.7368\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 1s 13us/step - loss: 0.7460 - acc: 0.7382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x127fa1a20>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=784))\n",
    "model.add(Dense(10, activation=\"relu\"))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, Y_train2, epochs=10, batch_size=100, verbose=1 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
