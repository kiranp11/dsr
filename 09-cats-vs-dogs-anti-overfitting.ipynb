{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats_vs_dogs_small : 3\n",
      "cats_vs_dogs_small/train : 2\n",
      "cats_vs_dogs_small/validation : 2\n",
      "cats_vs_dogs_small/test : 2\n",
      "cats_vs_dogs_small/train/cats : 1000\n",
      "cats_vs_dogs_small/train/dogs : 1000\n",
      "cats_vs_dogs_small/validation/cats : 500\n",
      "cats_vs_dogs_small/validation/dogs : 500\n",
      "cats_vs_dogs_small/test/cats : 500\n",
      "cats_vs_dogs_small/test/dogs : 500\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "\n",
    "original_dataset_dir = \"cats_vs_dogs/train\"\n",
    "\n",
    "dirs = []\n",
    "\n",
    "base_dir = \"cats_vs_dogs_small\"\n",
    "dirs.append(base_dir)\n",
    "\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "dirs.append(train_dir)\n",
    "validation_dir = os.path.join(base_dir, \"validation\")\n",
    "dirs.append(validation_dir)\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "dirs.append(test_dir)\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, \"cats\")\n",
    "dirs.append(train_cats_dir)\n",
    "train_dogs_dir = os.path.join(train_dir, \"dogs\")\n",
    "dirs.append(train_dogs_dir)\n",
    "\n",
    "validation_cats_dir = os.path.join(validation_dir, \"cats\")\n",
    "dirs.append(validation_cats_dir)\n",
    "validation_dogs_dir = os.path.join(validation_dir, \"dogs\")\n",
    "dirs.append(validation_dogs_dir)\n",
    "\n",
    "test_cats_dir = os.path.join(test_dir, \"cats\")\n",
    "dirs.append(test_cats_dir)\n",
    "test_dogs_dir = os.path.join(test_dir, \"dogs\")\n",
    "dirs.append(test_dogs_dir)\n",
    "\n",
    "for directory in dirs:\n",
    "    if not os.path.exists(directory):\n",
    "       os.mkdir(directory)\n",
    "    \n",
    "fnames = [\"cat.{}.jpg\".format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dest = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copy(src, dest)\n",
    "\n",
    "fnames = [\"cat.{}.jpg\".format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dest = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copy(src, dest)\n",
    "\n",
    "fnames = [\"cat.{}.jpg\".format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dest = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copy(src, dest)\n",
    "   \n",
    "fnames = [\"dog.{}.jpg\".format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dest = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copy(src, dest)\n",
    "\n",
    "fnames = [\"dog.{}.jpg\".format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dest = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copy(src, dest)\n",
    "\n",
    "fnames = [\"dog.{}.jpg\".format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dest = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copy(src, dest)\n",
    "\n",
    "for directory in dirs:\n",
    "    print(directory, \":\", len(os.listdir(directory)))\n",
    "    \n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "original_dataset_dir = \"cats_vs_dogs/train\"\n",
    "\n",
    "dirs = []\n",
    "\n",
    "base_dir = \"cats_vs_dogs_small\"\n",
    "dirs.append(base_dir)\n",
    "\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "dirs.append(train_dir)\n",
    "validation_dir = os.path.join(base_dir, \"validation\")\n",
    "dirs.append(validation_dir)\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "dirs.append(test_dir)\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, \"cats\")\n",
    "dirs.append(train_cats_dir)\n",
    "train_dogs_dir = os.path.join(train_dir, \"dogs\")\n",
    "dirs.append(train_dogs_dir)\n",
    "\n",
    "validation_cats_dir = os.path.join(validation_dir, \"cats\")\n",
    "dirs.append(validation_cats_dir)\n",
    "validation_dogs_dir = os.path.join(validation_dir, \"dogs\")\n",
    "dirs.append(validation_dogs_dir)\n",
    "\n",
    "test_cats_dir = os.path.join(test_dir, \"cats\")\n",
    "dirs.append(test_cats_dir)\n",
    "test_dogs_dir = os.path.join(test_dir, \"dogs\")\n",
    "dirs.append(test_dogs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(\n",
    "    32, (3, 3), \n",
    "    activation=\"relu\", \n",
    "    input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(512, activation=\"relu\"))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"acc\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## data generator: something that grabs something from somewhere: does data yield from dataset and rescaling\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen=ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40, #Data augmentation\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ") \n",
    "\n",
    "validation_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(\n",
    "                train_dir, #directory of the training set, with a subfolder for each class (here cats and dogs)\n",
    "                target_size=(150,150),\n",
    "                batch_size=20,\n",
    "                class_mode=\"binary\")\n",
    "\n",
    "validation_generator=validation_datagen.flow_from_directory(\n",
    "                    validation_dir,\n",
    "                    target_size=(150,150),\n",
    "                    batch_size=20,\n",
    "                    class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 63s 633ms/step - loss: 0.6934 - acc: 0.5165 - val_loss: 0.6882 - val_acc: 0.5000\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 68s 683ms/step - loss: 0.6822 - acc: 0.5600 - val_loss: 0.6723 - val_acc: 0.5870\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 66s 659ms/step - loss: 0.6770 - acc: 0.5750 - val_loss: 0.6572 - val_acc: 0.6080\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 66s 662ms/step - loss: 0.6615 - acc: 0.5900 - val_loss: 0.6431 - val_acc: 0.6110\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 66s 657ms/step - loss: 0.6529 - acc: 0.6135 - val_loss: 0.6370 - val_acc: 0.6470\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 93s 931ms/step - loss: 0.6275 - acc: 0.6470 - val_loss: 0.6304 - val_acc: 0.6320\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 71s 709ms/step - loss: 0.6248 - acc: 0.6510 - val_loss: 0.5977 - val_acc: 0.6770\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 67s 668ms/step - loss: 0.6168 - acc: 0.6630 - val_loss: 0.6397 - val_acc: 0.6140\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 69s 686ms/step - loss: 0.6000 - acc: 0.6770 - val_loss: 0.5793 - val_acc: 0.6840\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 69s 693ms/step - loss: 0.5921 - acc: 0.6835 - val_loss: 0.6538 - val_acc: 0.6420\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 71s 713ms/step - loss: 0.5822 - acc: 0.6970 - val_loss: 0.5791 - val_acc: 0.6910\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 69s 694ms/step - loss: 0.5873 - acc: 0.6900 - val_loss: 0.5843 - val_acc: 0.6880\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 71s 711ms/step - loss: 0.5740 - acc: 0.6950 - val_loss: 0.5747 - val_acc: 0.6870\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 70s 703ms/step - loss: 0.5723 - acc: 0.6990 - val_loss: 0.5308 - val_acc: 0.7260\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 70s 697ms/step - loss: 0.5672 - acc: 0.7115 - val_loss: 0.5362 - val_acc: 0.7190\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 72s 715ms/step - loss: 0.5572 - acc: 0.7145 - val_loss: 0.5355 - val_acc: 0.7300\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 70s 699ms/step - loss: 0.5589 - acc: 0.7115 - val_loss: 0.5147 - val_acc: 0.7400\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 70s 697ms/step - loss: 0.5404 - acc: 0.7250 - val_loss: 0.5136 - val_acc: 0.7500\n",
      "Epoch 19/30\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.5575 - acc: 0.7152"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=30,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [0.6698136699199676, 0.6427735674381256, 0.6319315254688262, 0.5893822890520096, 0.5709924590587616, 0.5721532118320465, 0.7697174292802811, 0.5366481083631516, 0.8196862834692001, 0.5889470165967942, 0.5462210887670517, 0.6168904668092727, 0.5762019434571266, 0.6159110790491105, 0.5603796964883805, 0.6156149238348008, 0.5976480287313461, 0.6007218837738038, 0.655026721060276, 0.6395707312226295, 0.7722695136070251, 0.7933874708414078, 0.8078887808322907, 0.8232916101813317, 0.7880340522527695, 0.7922880312800408, 0.8725620913505554, 0.894648485481739, 0.8905767714977264, 1.0313075387477875], 'val_acc': [0.6210000002384186, 0.63200000166893, 0.6330000001192093, 0.6880000007152557, 0.715000001192093, 0.7000000011920929, 0.62, 0.7200000011920928, 0.6239999997615814, 0.7070000004768372, 0.7339999997615814, 0.7129999989271164, 0.7369999992847442, 0.7340000033378601, 0.744000004529953, 0.7199999976158142, 0.742000002861023, 0.7470000016689301, 0.7369999992847442, 0.7309999978542328, 0.7219999980926514, 0.7200000011920928, 0.7179999995231628, 0.73299999833107, 0.7370000004768371, 0.7489999997615814, 0.739000004529953, 0.72799999833107, 0.73299999833107, 0.7320000016689301], 'loss': [0.6891725206375122, 0.6588887602090836, 0.6171622923016549, 0.5810840481519699, 0.5444785279035568, 0.5118648627400398, 0.47292701482772825, 0.44615003541111947, 0.41998582318425176, 0.39737928956747054, 0.36804584980010985, 0.3510716889798641, 0.3304330268502235, 0.296578471288085, 0.28452493518590927, 0.25985568810254334, 0.23362284936010838, 0.21463252745568753, 0.19099534317851066, 0.17643521359190345, 0.14824279498308898, 0.1291200215741992, 0.11432021735236049, 0.10447821971029043, 0.09508014244958758, 0.07200350039172917, 0.06473853703122585, 0.05766333224717528, 0.04320784237701446, 0.040072449278086425], 'acc': [0.5320000013709069, 0.6189999985694885, 0.6684999993443489, 0.6959999999403954, 0.7199999985098838, 0.7445000028610229, 0.7735000044107437, 0.7839999979734421, 0.8020000034570693, 0.8130000025033951, 0.8360000014305115, 0.8429999989271164, 0.8569999998807907, 0.8689999991655349, 0.8864999985694886, 0.8984999984502793, 0.904499990940094, 0.9139999943971634, 0.933499994277954, 0.9359999924898148, 0.9469999933242798, 0.9519999933242798, 0.964999994635582, 0.9664999961853027, 0.9714999949932098, 0.9804999971389771, 0.9849999982118607, 0.9854999977350235, 0.9894999980926513, 0.9909999984502792]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
