{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kprakash/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /Users/kprakash/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "import urllib\n",
    "from collections import Counter\n",
    "import html\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('perluniprops')\n",
    "from nltk import word_tokenize\n",
    "import pickle\n",
    "import random\n",
    "import progressbar\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tokenizer is nice, but could cause problems.\n",
    "try:\n",
    "    from nltk.tokenize.moses import MosesDetokenizer\n",
    "    detokenizer = MosesDetokenizer()\n",
    "    use_moses_detokenizer = True\n",
    "except:\n",
    "    use_moses_detokenizer = False\n",
    "\n",
    "\n",
    "# Corpus parameters.\n",
    "download_anyway = False\n",
    "corpus_url = \"https://archive.org/stream/shakespearessonn01041gut/wssnt10.txt\"\n",
    "corpus_path = \"shakespeare.txt\"\n",
    "\n",
    "# Preprocessing parameters.\n",
    "preprocess_anyway = False\n",
    "preprocessed_corpus_path = \"shakespeare.p\"\n",
    "most_common_words_number = 10000\n",
    "\n",
    "# Training parameters.\n",
    "train_anyway = True\n",
    "model_path = \"model.h5\"\n",
    "dataset_size = 5000\n",
    "sequence_length = 30\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "hidden_size = 1000\n",
    "\n",
    "# Generation parameters.\n",
    "generated_sequence_length = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_corpus_if_necessary():\n",
    "    \"\"\"\n",
    "    Downloads the corpus either if it is not on the hard-drive or of the\n",
    "    download is forced.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(corpus_path) or download_anyway == True:\n",
    "        print(\"Downloading corpus...\")\n",
    "\n",
    "        # Dowloading content.\n",
    "        corpus_string = urllib.request.urlopen(corpus_url).read().decode('utf-8')\n",
    "\n",
    "        # Removing HTML-stuff.\n",
    "        index = corpus_string.index(\"<pre>\")\n",
    "        corpus_string = corpus_string[index + 5:]\n",
    "        index = corpus_string.find(\"</pre>\")\n",
    "        corpus_string = corpus_string[:index ]\n",
    "        corpus_string = html.unescape(corpus_string)\n",
    "\n",
    "        # Write to file.\n",
    "        corpus_file = open(corpus_path, \"w\")\n",
    "        corpus_file.write(corpus_string)\n",
    "        corpus_file.close()\n",
    "\n",
    "        print(\"Corpus downloaded to\", corpus_path)\n",
    "    else:\n",
    "        print(\"Corpus already downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_corpus_if_necessary():\n",
    "    \"\"\"\n",
    "    Preprocesses the corpus either if it has not been done before or if it is\n",
    "    forced.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(preprocessed_corpus_path) or preprocess_anyway == True:\n",
    "        print(\"Preprocessing corpus...\")\n",
    "\n",
    "        # Opening the file.\n",
    "        corpus_file = open(corpus_path, \"r\")\n",
    "        corpus_string = corpus_file.read()\n",
    "\n",
    "        # Getting the vocabulary.\n",
    "        print(\"Tokenizing...\")\n",
    "        corpus_tokens = word_tokenize(corpus_string)\n",
    "        print(\"Number of tokens:\", len(corpus_tokens))\n",
    "        print(\"Building vocabulary...\")\n",
    "        word_counter = Counter()\n",
    "        word_counter.update(corpus_tokens)\n",
    "        print(\"Length of vocabulary before pruning:\", len(word_counter))\n",
    "        vocabulary = [key for key, value in word_counter.most_common(most_common_words_number)]\n",
    "        print(\"Length of vocabulary after pruning:\", len(vocabulary))\n",
    "\n",
    "        # Converting to indices.\n",
    "        print(\"Index-encoding...\")\n",
    "        indices = encode_sequence(corpus_tokens, vocabulary)\n",
    "        print(\"Number of indices:\", len(indices))\n",
    "\n",
    "        # Saving.\n",
    "        print(\"Saving file...\")\n",
    "        pickle.dump((indices, vocabulary), open(preprocessed_corpus_path, \"wb\"))\n",
    "    else:\n",
    "        print(\"Corpus already preprocessed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network():\n",
    "    \"\"\"\n",
    "    Trains the corpus either if it has not been done before or if it is\n",
    "    forced.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(model_path) or train_anyway == True:\n",
    "\n",
    "        # Loading index-encoded corpus and vocabulary.\n",
    "        indices, vocabulary = pickle.load(open(preprocessed_corpus_path, \"rb\"))\n",
    "\n",
    "        # Get the dataset.\n",
    "        print(\"Getting the dataset...\")\n",
    "        data_input, data_output = get_dataset(indices)\n",
    "        data_output = utils.to_categorical(data_output, num_classes=len(vocabulary))\n",
    "\n",
    "        # Creating the model.\n",
    "        print(\"Creating model...\")\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Embedding(len(vocabulary), hidden_size, input_length=sequence_length))\n",
    "        model.add(layers.LSTM(hidden_size))\n",
    "        model.add(layers.Dense(len(vocabulary)))\n",
    "        model.add(layers.Activation('softmax'))\n",
    "        model.summary()\n",
    "\n",
    "        # Compining the model.\n",
    "        print(\"Compiling model...\")\n",
    "        model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['categorical_accuracy']\n",
    "        )\n",
    "\n",
    "        # Training the model.\n",
    "        print(\"Training model...\")\n",
    "        history = model.fit(\n",
    "            data_input, data_output,\n",
    "            epochs=epochs, batch_size=batch_size)\n",
    "        model.save(model_path)\n",
    "        plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(indices):\n",
    "    \"\"\" Gets a full dataset of a defined size from the corpus. \"\"\"\n",
    "\n",
    "    print(\"Generating data set...\")\n",
    "    data_input = []\n",
    "    data_output = []\n",
    "    current_size = 0\n",
    "    bar = progressbar.ProgressBar(max_value=dataset_size)\n",
    "    while current_size < dataset_size:\n",
    "\n",
    "        # Randomly retriev a sequence of tokens and the token right after it.\n",
    "        random_index = random.randint(0, len(indices) - (sequence_length + 1))\n",
    "        input_sequence = indices[random_index:random_index + sequence_length]\n",
    "        output_sequence = indices[random_index + sequence_length]\n",
    "\n",
    "        # Update arrays.\n",
    "        data_input.append(input_sequence)\n",
    "        data_output.append(output_sequence)\n",
    "\n",
    "        # Next step.\n",
    "        current_size += 1\n",
    "        bar.update(current_size)\n",
    "    bar.finish()\n",
    "\n",
    "    # Done. Return NumPy-arrays.\n",
    "    data_input = np.array(data_input)\n",
    "    data_output = np.array(data_output)\n",
    "    return (data_input, data_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_texts():\n",
    "    \"\"\" Generates a couple of random texts. \"\"\"\n",
    "\n",
    "    print(\"Generating texts...\")\n",
    "\n",
    "    # Getting all necessary data. That is the preprocessed corpus and the model.\n",
    "    indices, vocabulary = pickle.load(open(preprocessed_corpus_path, \"rb\"))\n",
    "    model = models.load_model(model_path)\n",
    "\n",
    "    # Generate a couple of texts.\n",
    "    for _ in range(10):\n",
    "\n",
    "        # Get a random temperature for prediction.\n",
    "        temperature = random.uniform(0.0, 1.0)\n",
    "        print(\"Temperature:\", temperature)\n",
    "\n",
    "        # Get a random sample as seed sequence.\n",
    "        random_index = random.randint(0, len(indices) - (generated_sequence_length))\n",
    "        input_sequence = indices[random_index:random_index + sequence_length]\n",
    "\n",
    "        # Generate the sequence by repeatedly predicting.\n",
    "        generated_sequence = []\n",
    "        generated_sequence.extend(input_sequence)\n",
    "        while len(generated_sequence) < generated_sequence_length:\n",
    "            prediction = model.predict(np.expand_dims(input_sequence, axis=0))\n",
    "            predicted_index = get_index_from_prediction(prediction[0], temperature)\n",
    "            generated_sequence.append(predicted_index)\n",
    "            input_sequence = input_sequence[1:]\n",
    "            input_sequence.append(predicted_index)\n",
    "\n",
    "        # Convert the generated sequence to a string.\n",
    "        text = decode_indices(generated_sequence, vocabulary)\n",
    "        print(text)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_from_prediction(prediction, temperature=0.0):\n",
    "    \"\"\" Gets an index from a prediction. \"\"\"\n",
    "\n",
    "    # Zero temperature - use the argmax.\n",
    "    if temperature == 0.0:\n",
    "        return np.argmax(prediction)\n",
    "\n",
    "    # Non-zero temperature - do some random magic.\n",
    "    else:\n",
    "        prediction = np.asarray(prediction).astype('float64')\n",
    "        prediction = np.log(prediction) / temperature\n",
    "        exp_prediction= np.exp(prediction)\n",
    "        prediction = exp_prediction / np.sum(exp_prediction)\n",
    "        probabilities = np.random.multinomial(1, prediction, 1)\n",
    "        return np.argmax(probabilities)\n",
    "\n",
    "\n",
    "def encode_sequence(sequence, vocabulary):\n",
    "    \"\"\" Encodes a sequence of tokens into a sequence of indices. \"\"\"\n",
    "\n",
    "    return [vocabulary.index(element) for element in sequence if element in vocabulary]\n",
    "\n",
    "\n",
    "def decode_indices(indices, vocabulary):\n",
    "    \"\"\" Decodes a sequence of indices and returns a string. \"\"\"\n",
    "\n",
    "    decoded_tokens = [vocabulary[index] for index in indices]\n",
    "    if use_moses_detokenizer  == True:\n",
    "        return detokenizer.detokenize(decoded_tokens, return_str=True)\n",
    "    else:\n",
    "        return \" \".join(decoded_tokens)\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    \"\"\" Plots the history of a training. \"\"\"\n",
    "\n",
    "    print(history.history.keys())\n",
    "\n",
    "    # Render the loss.\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig(\"history_loss.png\")\n",
    "    plt.clf()\n",
    "\n",
    "    # Render the accuracy.\n",
    "    plt.plot(history.history['categorical_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig(\"history_accuracy.png\")\n",
    "    plt.clf()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\" The main-method. Where the fun begins. \"\"\"\n",
    "\n",
    "    download_corpus_if_necessary()\n",
    "\n",
    "    preprocess_corpus_if_necessary()\n",
    "\n",
    "    train_neural_network()\n",
    "\n",
    "    generate_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5000 of 5000) |####################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus already downloaded.\n",
      "Corpus already preprocessed.\n",
      "Getting the dataset...\n",
      "Generating data set...\n",
      "Creating model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 1000)          3583000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1000)              8004000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3583)              3586583   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3583)              0         \n",
      "=================================================================\n",
      "Total params: 15,173,583\n",
      "Trainable params: 15,173,583\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Compiling model...\n",
      "Training model...\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 82s 16ms/step - loss: 6.8634 - categorical_accuracy: 0.0780\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 85s 17ms/step - loss: 6.0605 - categorical_accuracy: 0.0874\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 85s 17ms/step - loss: 5.8108 - categorical_accuracy: 0.0938\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 87s 17ms/step - loss: 5.5598 - categorical_accuracy: 0.1046\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 83s 17ms/step - loss: 5.2534 - categorical_accuracy: 0.1248\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 4.8905 - categorical_accuracy: 0.1624\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 4.4587 - categorical_accuracy: 0.2126\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 86s 17ms/step - loss: 3.9983 - categorical_accuracy: 0.2562\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 84s 17ms/step - loss: 3.5257 - categorical_accuracy: 0.3158\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 3.2941 - categorical_accuracy: 0.3412\n",
      "dict_keys(['loss', 'categorical_accuracy'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating texts...\n",
      "Temperature: 0.8886598878902081\n",
      "do count the clock that tells the time , And see the brave day sunk in hideous night ; When I behold the violet past prime , And sable curls were Or , The April , when they praise , Then , that thou my heart , And he is eyes , most ever from not of her think To your The age , And greet that nymphs of worship dignifies his love and from : Mine love , A more in thy way what making in thy for me alive thy with me what to mourn what governs so ; Yet Nature wrongfully wood to be , and thine whose as by another sure Give those . fears to lies , and in thy memory not , and old , Love put thy O ! in O ! Or , To the how to external , Plods Shall , Though they other that 'Will : Then , And stays , wide basest itself not and dwell : behind , So should not most ; Or ten thy Nor sullen . but and this say , keeps , which this character , And that I eyes of thy aid . vengeful can together strong paws of me But my love striving to thy lusty . not heavy that thou hot upon well . of thy subject and fire : though Love is not most will But in thee action ; The Why should three-fold 'd , will they what of a youth I worth be love , Bound pale must indirectly to such me then in me well was be that I paws by duty , Make took the If his affords , And excuse will ; Nor truly will part oft merit 's shop . In bring , That with me black , That did I foul . LIII winters be may thy beauty is ; For mutual me thy sweet dost which be mud : My for me to read thy thy power much , or each thou all nothing groan and possession of thy sweet sight , Make more so imitate , Plods despair itself me shows strong content . treads : 'T is with her no permit remembered , yet all O , And they for my heart , But far in tyrants took bereft . behind ; and this shaken ; Nor basest itself with me of love , kind , but shall I say my heart 's showers permit Lose , Though in tenure may be hell is to green , But they by chase . Be , Nor physician the In me are public contains to me upon as over 'Amen' To Simply beauty still thee : Then , And have governs it with my verse doth all they deem'd , The master dare I will , when in a Lose Want vengeful , Thy April must ' should . like me That ears , Whilst more still am hear , To all\n",
      "\n",
      "Temperature: 0.5927911070778651\n",
      "and thy dear virtue hate , Hate of my sin , grounded on sinful loving : O ! but with mine compare thou thine own state , And thou shalt eisel in thy thought : But simple perfumes ; In Love , In those 'd ; And keep , When I have ; And all be remain ; Tell glad eyes of thy book . In may love , That what as thine , And simple a covetous , And ever , And they sav of my strong world to conscience basest , And by what of her , And well 'd with as thy Without me afresh . I have : LXXVI Those from me , And that I have ; And you , That I have ; And at they him , In love , Though in a No , And was me external ' at that stand , now is not thy power me , but what from my thoughts of Time . XCII having , The If thy songs and those . None thy gaze , And Love 's leap 'd : But that I have ; And pour'st his orient day , And thou be skill of me , To Those lips . Yet , And basest on thee , When that I still my 'T is The or hold me , And thy love , When I have ; And do thy love 's wilt be . The region is on thee , With not I love , The If thy Thy age , As might my love , yet heaven 's XL ocean To be well , When I love can not so or me , The beauty is a beauty to thy XCII belov , thy On is thy XL compare , To thy private . The If I should be nymphs , It did thy Why should love , When I in thy mountain . In term 'd , Or , And for my barren of thy mind , To thy show me . Then , And him was can I most I good so gazers For canker beauty is ; Harsh thine could , That hath my love , The basest were fiery by outworn , So by thy heart . In cunning , The basest do were If thy much , seeing much , nor my I think , And my love , Nor own beauty ! And since that I have ; And ; For feeds : In As , and heavily can thy Yet , and do not more ; And eyes . CXLIX at my light . That those from it 's good and those . Then , And slander 's thy beauty . But pour'st me ? Then , And thine may thou my love , Nor If thy bids her , Yet thy fiery : that thou were depart And that I those . LXXXVIII commits , The Why is a spoil and let\n",
      "\n",
      "Temperature: 0.2376836285842414\n",
      ", yet receives rain still , And in abundance addeth to his store ; So thou , being rich in 'Will , ' add to thy 'Will' One will of thy beauty is my love , And in thy beauty is of thee , And that I have ; And him to my love , And that I have ; And that I have ; And that I have ; And do they may to thy beauty is not so , And that I have ; And him have ; And simple , And that I have ; The basest prisoner many : Then , And bare , And that I have ; And they for my heart , And in thy heart 's face , To thy love , And in thy parts . In basest , And those of thy beauty is my love , And that I have ; And they from thy parts , And all thy advocate , And that thy beauty is my love , And that I have ; And that I have ; And they be , And simple , And thy show , And that I have ; And do thy power they him . Then , And ten , When I have I swear ; And him from my love , And that I have ; And that I have ; And that I have ; And that I love , The basest is my love , all thy beauty is my love , And that thy pure basest , And those of thee , And in thy parts . In basest , and he is thy beauty is my love , The basest lips . XXVIII may thy beauty is my love , And in thy love , And my love , And that thy fiery , In thy love , And thy love , And thy sweet love , And that I have ; And for my heart , And they thy beauty is my mind , And that thy beauty is my love , And that thy love , And in thy beauty is my love , When I say , and he is those . In more , When I have ; And him , As , And him to my heart ; And that I have ; And him to my heart , And that I have ; But which is it to my love , And that I have ; The basest should my love , And thy love , And that thy love , So do thy love , And thy love , And in thy parts , And my love , And thy love , And in thy sweet love , And that I have ; And that I have ; And for my love , And in thy As , And thy love , And all thy parts , And do thy love , And that I have ; And that\n",
      "\n",
      "Temperature: 0.7784155528115082\n",
      "make time 's spoils despised every where . Give my love fame faster than Time wastes life , So thou prevent'st his scythe and crooked knife . CI O truant ; And feeds must most Give not I would , When him , Yet , When I have ; And pleased I silence , All this bear . Then , To others of clearer thy show . When I must these , When that . Divert , and straight , That did the which is my thoughts : Yet , and thine what thy kind-hearted : 'T is thy CXLV worthy December put beauty lips . XL lives his happy do thy put my love so hunted and thy ignorance no still : Profitless thy lov'st private , So should thorns shows , Now is . of thee . That did I never set from thy random basest to thy too him . determination be ? When Eve : vial , And only this their o'er shows to me , That did thine groan your enemies his heaven 's comments . In must love to Bare When becomes me rhymers . O ten to find thy sake : stays do adieu governs , It , And those they kinds , cruel old , And act 'd wombs upon : life , love by barren fire ; Yet him were O ! O ! art others . O ! Love by thy beauties may the My love , And thy love can not thee , green : forfeit out of stand . O ! black so thy or night , Though in youngly is . Then , And Fortune by sad O ! mine may as thy wit , The basest , love have : Then must so wail they one , But those from thy sad many : do all worms , nothing should my love 's have ; In those upon should : Yet , to their over must that thou into , In Who , are term 'd releasing ; I did I fast no cherubins must done thy unless thou man : are , do thy 'Will . ' doth thy like ; That did thy confine hope should worthiness ; And their love say their love , And When with my novel , When most how not most all thee as thy fever worst Lose one . My physician love 's mayst O ! That feeds on thy part glad touches . perfumes in a cold : another gaze debarre we many found , to therefore , In merit of ; And ever , To thine doth as thy love to thy beauty am ; And pour'st me , Yet is my verse , That should were yours 's foe , To what they purge , Against my My so else be on external now your ears . And make my love to most sullen : CXIX my Much must proud Want need . In counting\n",
      "\n",
      "Temperature: 0.08859265409936312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so grounded inward in my heart . Methinks no face so gracious is as mine , No shape so true , no truth of such account ; And for myself , And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have ; And that I have\n",
      "\n",
      "Temperature: 0.6571012955219723\n",
      "love to any , Who for thy self art so unprovident . Grant , if thou wilt , thou art belov 'd of many , But that thou none lov'st own beauty to thee ; And many a ushers , When I return 'd my life , And in thy defect is the winters ! each doth thy soul 's put cold , And do not than I bring ; And mutual thy life , When him his writ , And that I have ; And was will endure , When thine whose not eye 's December No , And pour'st is do And to that which it ? Thy basest eyes . basest hath my thine no delight . Then , And those me towards see his In be December breath to 'Amen' Why eyes , age , and make his forty age , And this not , And he with my love 's fear : In vouchsafe me , and pleased is on , That , And from thy lovely translated , When I have I swear 'd of my self I have ; Then December will smell , In think , And us have ; But make his parts . In basest should in me , Yet what thy mine , That from my thine , And counting my herself : present thy dream . In act ; love , kind , can him must not I could , An by me , And him for thy parts , The make me ! In divine in your keep , And in thy yours , And thine from my sightless Yet , And all thy Weighs : The basest they have ; And worse from thy lusty of thy CXLII which gives , The If I be from thy waves : Dost they vengeful to Death , When strength of thy tyrants Lord to Thus of me , To thy 'Will . And many that still , and he 's curious : XLV in thy shows , In each is my most no child ! show , and beauty is my what no youth , When I love , love , Much of thy due , and Was will eyes , That ten , Yet , In thy No , And he to can thy let , When I cunning , And many a in my love , When all thy worthy of thy of me then nymphs upon ; And hate , And to me , Or and shown ; so , And they shall I do Then , to vouchsafe me . Then hath my mind , Beauty him , And dost into writ , And all thy thanks leap , And they itself , And him with thee of thy parts may not it to your beauty is my love and under . In think , love him would by thy Love 's desire , When I shows , And that thou thee , And\n",
      "\n",
      "Temperature: 0.45807009420672684\n",
      "this coming end you should prepare , And your sweet semblance to some other give : So should that beauty which you hold in lease Find no determination ; then thy love to my love , And you were immortal . I do I have I have ; But pour'st me The Who , That they what in thy book . LXXXIX may thy tables doth depend . In much , nor my love , The basest is not to my love , and thee ; For Those of be , And make me so from thy beauty is thy Why is thy parts , and thy heart . not As , And put thy For which is . Then , And pour'st me well . O ! And for my wander'st in thy love , And , And him upon ; And with my dear , And thy love , And that to my heart . In let , The basest is my pity And for my fiery . dearest , And that I have ; And that I have ; And from my Or , and thy heart of thy beauty is my O ! In Shall , Thou of thy show , That did you . Then , And eyes of thee , When I have I of thy part we . In think , And him were keeps , When I have ; For play'st they what with his beauty . That thou my love , When I have ; And thine , When I have ; And yourself , The basest lips . Then , And grew worse . In basest should so it . In basest , And dost thou proud black one , When I love to thy beauty doth all thy love , The basest must be , And that thy not , can thy love , and each is of thy heart 's love , And my love , not thy sum , The basest must -- To most I have ; And keep , And that thou in me , and he is spoil And shall I say , And that thou a Then ? And If thy your beauty is thy Thy Want we , nor my love , Beauty , And do thy part part his And that you . Then , And thy show him . Then , And most I say , love , And you , As , And shoot from my trees Shall , but thy not , And in thy Yourself no The O ! The region is not so from my mind , The basest is my verse , And that I swear . In basest I have ; And him . Now is of my love , And that thy Of that I am ; And this , And their sweet love , When I have I of thee ; And that I eyes , When I have ; And in\n",
      "\n",
      "Temperature: 0.6704304728622313\n",
      ". Dear my love , you know , You had a father : let your son say so . XIV Not from the stars do I my judgement pluck ; In I have ; Yet enemies may The tongue-tied by thy On ; And will of his thoughts of my heart 's o'er-read ; That may have writes , And thou the Then , And did I am may The think may as that I other that as him they think with be remain , wherein I was : Lest Those The cloud they those . Look O ! before of thy scorn to invoked , LXIX . Be , And they keep , if in will black so not not A basest I of thee . In among of forfeit from the shames and her shows hath my verse no Therefore you were Then , And mutual this CLIII , And for my slave to make me well so ? That made a nature to your from my name under . wound is thy advocate , And in thy far . XL where my even to free , And ever , which they Hath promise impeach 'd ; That did I of thee . I do mine contented : Although , To make me , As , And April , To pour'st spirit of me , Nor were heavy complexion the twofold me . let slay me as thy happy day , So pour'st that which ; And in a new . Leese me , That ever thy And to these , Or , Yet , nor thy before dost holds ; And us on thee ; And you of my heart 's frown may my random faith every splendour should thy As , to be heart ? seeing , in their dumb thoughts thy cruel me not give thy jewel . Tell since all thy cruel of thy hue : For vouchsafe me , And that I have ; And turns is my part his Love is my be thoughts from thy part ever , Thy thing how thy Love ? And wish in me so still , And all thy orient must some bring : Yet did I have ; And most Sweet grief , Nor false of your being they thy advocate , And me , When I in thy Till Why is my love , Distill , Love , And strength of thy parts , Bound when they sickness to my heart 's face , and old , And all thy yellow , When I must what they III , love , -- what must not so still , With did I have I think have ; And you in my heart , And strange , and my heart , And this you , Which did thy show , nor my happy Are what upon have ; And him , moving , And do I thine green . which was up that all thy hours\n",
      "\n",
      "Temperature: 0.41948871000164134\n",
      "to anticipate The ills that were not , grew to faults assur 'd , And brought to medicine a healthful state Which , rank of goodness , would by ill . Then , to all thy happy for my heart , And that you ? Then , And simple , And that thou those . In basest , And prayers rage And ever , And my heart 's face , And that thy sweet love . But they must , And him of my thoughts of thy beauty is my self , And that thou , And simple , And shall I am I have ; And do I say , Though I have ; And that I have ; And thou my heart , And that which me , and he is still , Nor term 'd . Then , But are , And be have ; And do happy I love , And my love , And that thy delight . stand , The basest should my verse 's use And make thy make me . Then , And worthy I say , And for my love , And my love , As , And by thy joy O ! And truly for my love , That did in their nothing me , As , And thy love 's face , And thy heart 's strong Shall . not I good , and they from my memory thy In eye 's issueless night , That did I from my sightless To him in my heart 's depend . In earth , When I have ; And do they charter so not so by thy That ? To much , And for my love , In thy heart . In basest I have ; And this , And did I have ; When I have ; And him by beauties gather need . In basest , And do they you . In I hold thy sweet heart , And that thy book . Be , When I have ; And they be well , That him to their beauty is my heart 's remov . For What how to my love , And that I loves And make thy light hate , So do mine may not all thy like a better ; And that I most I have ; The basest itself , And pour'st me , And thy sweet love , That did I from my heart , and thy sweet love , That did I by me , And that I have : For do thy 'Will of thy fairest translated , Unless I stand . In that which ; And that I in my way no towards , And they from thy A ocean world , When I love to my love , and old , And truly show , to be mayst be How O ! what they do I do I must be , And I in my love and thy beauty is\n",
      "\n",
      "Temperature: 0.24901487855127769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vow debate , For I must ne'er love him whom thou dost hate . XC Then hate me when thou wilt ; if ever , now ; Now , while my love , And my love , And they for my love , And that I have ; And him will most I have ; The basest how to be , And do I do they worthy I have ; And that I have ; And that I have ; The basest I have ; And he is it to those . In thought , And my love , And that I have ; And you , And that I have ; And that which ; And that I have ; The basest they a Then , And in me well . Then , And pour'st me and me , And that thy heart 's face , And thy heart 's face , And thy beauty is my mind , And that I say , nor my love , nor thy love , and thy love , And that I have ; And that I have ; And that I have ; And that I have ; But they must I of thy heart . In basest , And him to my love , And in thy pure vainly . For If thy memory they Eve , In thy love , And thy love , And in thy love , And that I have ; And do thy love , The basest must have ; And that thou were be say , And that I do O ! In glad how to thee , And thy love , And what they was I have ; And that I have ; And that I have ; But they be , And many me , And that I have ; For him to my thoughts . In basest , And that I have ; And that I have ; For I have ; And simple , And every power of me , And that thy sins . In be , And him to my love , And that I have ; And him , As , And him , and thy heart doth thy beauty to thy beauty is my love , And that I say , And that I have ; And him , When I have ; And him to that I love , The basest must , And he can have ; And that I have ; And him they my love , And that I have ; And that I have ; And that I have ; And by thy heart 's face , And that I have ; And that I have ; That did I have ; And that I have ; And that I do I have ; For do thy grave they have ; And all thy mind , And that I have ; And that I have ; And that I have ;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
